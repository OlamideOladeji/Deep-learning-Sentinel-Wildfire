{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from owslib.wms import WebMapService\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely    # if unable pip install Shapely\n",
    "from datetime import datetime\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from geolocation import GeoLocation  #You need to have geolocation.py in the same directory\n",
    "import cv2    #If uninstalled do pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Downloaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire19 = gpd.read_file('2019_perimeters_dd83.shp') #downloaded from GeoMACwebsite\n",
    "fire18 = gpd.read_file('2018_perimeters_dd83.shp')\n",
    "fire17 = gpd.read_file('2017_perimeters_dd83.shp')\n",
    "fire16 = gpd.read_file('2016_perimeters_dd83.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "frames = [fire19, fire18, fire17, fire16]\n",
    "#all_fires = pd.concat(frames)\n",
    "all_fires = gpd.GeoDataFrame( pd.concat( frames, ignore_index=True) )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_fires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading for single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAutomatedBbox(centroid_lon, centroid_lat, distance):\n",
    "    loc = GeoLocation.from_degrees(centroid_lat, centroid_lon)\n",
    "    #distance = 1 \n",
    "    (SW_loc, NE_loc) = loc.bounding_locations(distance)\n",
    "    min_lat =  SW_loc.deg_lat\n",
    "    min_lon =  SW_loc.deg_lon\n",
    "    max_lat =  NE_loc.deg_lat\n",
    "    max_lon =  NE_loc.deg_lon\n",
    "    Bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "    \n",
    "    return Bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample use\n",
    "i = 9\n",
    "distance = 0.5\n",
    "if type(all_fires['geometry'][i]) == shapely.geometry.polygon.Polygon:\n",
    "    test_polygon = all_fires['geometry'][i]\n",
    "    ade_center = np.array(test_polygon.representative_point()) \n",
    "    polybbox = getAutomatedBbox(ade_center[0], ade_center[1], distance)\n",
    "elif type(all_fires['geometry'][i]) == shapely.geometry.multipolygon.MultiPolygon:\n",
    "    test_polygon = all_fires['geometry'][i][0]\n",
    "    ade_center = np.array(test_polygon.representative_point()) \n",
    "    polybbox = getAutomatedBbox(ade_center[0], ade_center[1], distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms = WebMapService('http://services.sentinel-hub.com/ogc/wms/259ecbcc-6ac9-424a-ad00-55ae902cd1df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the same image using centroid approach\n",
    "fire_imgnew = wms.getmap(  \n",
    "                    layers=['TRUE_COLOR'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2019-05-05/2019-05-05',        #may 23 (05, 24) to july 1st>             \n",
    "                     )\n",
    "\n",
    "decoded = cv2.imdecode(np.frombuffer(fire_imgnew.read(), np.uint8), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Sentinel Images to Match Perimeter Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel images are pictures of plots of land from the Sentinel Satelite with multiple types of features (vegetation, etc.). The images are taken every 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms = WebMapService('http://services.sentinel-hub.com/ogc/wms/259ecbcc-6ac9-424a-ad00-55ae902cd1df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary exploration of WMS options/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Copernicus project’s Sentinel satellites are revolutionizing earth observation (EO). Its free, full and open access to data with very short revisit times, high spatial resolution, and good spectral resolution are crucial for many applications. The portfolio of possible products is vast - use-cases of such a service range from plant health monitoring, land and water body change, flood monitoring, disaster mapping and more.However the current gap between Sentinel source data and its end-users is large:• \\x90  ESA’s complex Scientific Data Hub• \\x90  raster files are compressed with JPEG2000 (13 raster filesfor each product, one per spectral band)• \\x90  terabytes of data per week• \\x90  additional processing requirementsTackling the data in an old-fashioned way -  offering individual derivative products simply does not work anymore, the associated time and costs are large and defeat most of the major benefits of the Sentinel project.Our approach combines cloud-based GIS technologies, parallel processing and fully automated procedures. To support the fast developing EO field we provide tools directly to end-users. on-the-fly processing and visualization make it possible to build new products (e.g. vegetation indices and similar) in a matter of minutes.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wms.identification.type\n",
    "wms.identification.version\n",
    "wms.identification.title\n",
    "wms.identification.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGRICULTURE',\n",
       " 'ARI1',\n",
       " 'ARI2',\n",
       " 'ATMOSPHERIC_PENETRATION',\n",
       " 'B01',\n",
       " 'B02',\n",
       " 'B03',\n",
       " 'B04',\n",
       " 'B05',\n",
       " 'B06',\n",
       " 'B07',\n",
       " 'B08',\n",
       " 'B09',\n",
       " 'B10',\n",
       " 'B11',\n",
       " 'B12',\n",
       " 'B8A',\n",
       " 'BAI',\n",
       " 'BATHYMETRIC',\n",
       " 'CHL_RED_EDGE',\n",
       " 'CRI1',\n",
       " 'CRI2',\n",
       " 'EVI',\n",
       " 'EVI2',\n",
       " 'FALSE_COLOR',\n",
       " 'FALSE_COLOR_URBAN',\n",
       " 'GEOLOGY',\n",
       " 'GRVI1',\n",
       " 'LAI_SAVI',\n",
       " 'MOISTURE_INDEX',\n",
       " 'MSAVI2',\n",
       " 'NBR_RAW',\n",
       " 'NDVI',\n",
       " 'NDVI_GRAY',\n",
       " 'NDVI_GREEN_GRAY',\n",
       " 'NDWI',\n",
       " 'PSRI',\n",
       " 'PSRI_NIR',\n",
       " 'RED_EDGE_NDVI',\n",
       " 'RE_NDWI',\n",
       " 'RGB_11_8_3',\n",
       " 'RGB_4_3_1',\n",
       " 'RGB_8_11_12',\n",
       " 'RGB_8_11_4',\n",
       " 'RGB_8_5_4',\n",
       " 'RGB_8_6_4',\n",
       " 'SAVI',\n",
       " 'SWIR',\n",
       " 'TRUE_COLOR']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wms.contents)  #see list of options for types of features available from Sentinel Satelites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': {'title': 'default'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wms['TRUE_COLOR'].styles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GetCapabilities', 'GetMap', 'GetFeatureInfo']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.name for op in wms.operations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Get',\n",
       "  'url': 'http://services.sentinel-hub.com/ogc/wms/02ea2542-7c5b-403a-bcc9-20f8618af983?'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wms.getOperationByName('GetMap').methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application/xml',\n",
       " 'text/xml',\n",
       " 'application/vnd.ogc.wms_xml',\n",
       " 'application/vnd.ogc.gml',\n",
       " 'text/html',\n",
       " 'application/json',\n",
       " 'text/plain']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wms.getOperationByName('GetFeatureInfo').formatOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through and download more images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_perims = all_fires.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def getSearchIntervalNew(fire_perims,i, isFire):\n",
    "    \"\"\"Finds a 10 day time interval matching when fire happened for ith instance of a fire\"\"\"\n",
    "    \"\"\"For non-fire, check 5 months prior for same location where fire burned\"\"\"\n",
    "    # pull date from fire_perims and reformat it\n",
    "    #date = fire_perims['DATE'].iloc[i,]\n",
    "    date = fire_perims['perimeterd'][i]\n",
    "    \n",
    "    # Reinterpret the date as a datetime and save as a string\n",
    "\n",
    "    firedate = dt.datetime.strptime(date, '%Y-%m-%d')\n",
    "    firedate_str = firedate.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if isFire:\n",
    "        # Calculate the date that is 10 days in the future to be the end of the time interval we want an image\n",
    "        interval_enddate = firedate + dt.timedelta(days = 5)  #can reduce if needed\n",
    "        # interval_enddate = interval_enddate.now()\n",
    "        interval_enddate_str = interval_enddate.strftime(\"%Y-%m-%d\")\n",
    "        # Construct date interval\n",
    "        search_interval = firedate_str + '/' + interval_enddate_str \n",
    "    else:\n",
    "        interval_startdate = firedate - dt.timedelta(days = 300)\n",
    "        interval_enddate = interval_startdate + dt.timedelta(days = 30)\n",
    "        search_interval = interval_startdate.strftime(\"%Y-%m-%d\") + '/' + interval_enddate.strftime(\"%Y-%m-%d\")  \n",
    "    \n",
    "    return (search_interval, str(firedate.strftime(\"%Y\")))\n",
    "\n",
    "\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Images as NP_Arrays (New code written on March 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_polygon = all_fires['geometry'][0]\n",
    "poly_center = np.array(test_polygon.representative_point()) \n",
    "polygonbounds = getAutomatedBbox(poly_center[0], poly_center[1], distance)\n",
    "\n",
    "image_request_true = wms.getmap(  \n",
    "                    layers=['TRUE_COLOR'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polygonbounds,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2018-04-05/2019-04-05',        #may 23 (05, 24) to july 1st>             \n",
    "                     )\n",
    "image_request_ndvi = wms.getmap(  \n",
    "                    layers=['NDVI'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2018-04-05/2019-04-20',        #may 23 (05, 24) to july 1st>             \n",
    "                     )\n",
    "image_request_nbr = wms.getmap(  \n",
    "                    layers=['NBR_RAW'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2018-04-05/2019-04-20',        #may 23 (05, 24) to july 1st>             \n",
    "                     )\n",
    "                     \n",
    "    \n",
    "image_request_bai = wms.getmap(  \n",
    "                    layers=['BAI'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2018-04-05/2019-04-20',        #may 23 (05, 24) to july 1st>             \n",
    "                     )\n",
    "\n",
    "\n",
    "image_array_true = cv2.imdecode(np.frombuffer(image_request_true.read(), np.uint8), -1)\n",
    "image_array_ndvi = cv2.imdecode(np.frombuffer(image_request_ndvi.read(), np.uint8), -1)\n",
    "image_array_nbr = cv2.imdecode(np.frombuffer(image_request_nbr.read(), np.uint8), -1)\n",
    "image_array_nbr = image_array_nbr[..., np.newaxis]\n",
    "image_array_bai = cv2.imdecode(np.frombuffer(image_request_bai.read(), np.uint8), -1)\n",
    "image_array_bai = image_array_bai[..., np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_array_all = np.concatenate((image_array_true, image_array_ndvi, image_array_nbr, image_array_bai), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 8)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   ALL IMAGES\n",
    "#### Helper function for getting array For all images (256 x 256 x 12 channels x m examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDownloadImageArray(polygonbounds, timeparams, date):\n",
    "    image_request_true = wms.getmap(  \n",
    "                    layers=['TRUE_COLOR'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polygonbounds,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time =timeparams,                    \n",
    "                     )\n",
    "    image_request_ndvi = wms.getmap(  \n",
    "                    layers=['NDVI'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time =timeparams,                  \n",
    "                     )\n",
    "    image_request_nbr = wms.getmap(  \n",
    "                    layers=['NBR_RAW'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time =timeparams,           \n",
    "                     )\n",
    "                     \n",
    "    \n",
    "    image_request_bai = wms.getmap(  \n",
    "                    layers=['BAI'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polybbox,\n",
    "                     size=(256, 256),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time =timeparams,                    \n",
    "                     )\n",
    "\n",
    "\n",
    "    image_array_true = cv2.imdecode(np.frombuffer(image_request_true.read(), np.uint8), -1)\n",
    "    image_array_ndvi = cv2.imdecode(np.frombuffer(image_request_ndvi.read(), np.uint8), -1)\n",
    "    image_array_nbr = cv2.imdecode(np.frombuffer(image_request_nbr.read(), np.uint8), -1)\n",
    "    #if image_array_nbr is None:\n",
    "    #    return []\n",
    "\n",
    "    image_array_nbr = image_array_nbr[..., np.newaxis]\n",
    "    image_array_bai = cv2.imdecode(np.frombuffer(image_request_bai.read(), np.uint8), -1)\n",
    "    #if image_array_bai is None:\n",
    "    #    return []\n",
    "    image_array_bai = image_array_bai[..., np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "    if np.sum(image_array_true) < (256*256*8*255*0.9):    #if the image is not too white\n",
    "        image_array_all = np.concatenate((image_array_true, image_array_ndvi, image_array_nbr, image_array_bai), axis=-1)\n",
    "        return image_array_all\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "        \n",
    "        \n",
    "def downloadAllBurnImagesAsArray(fire_perims, isFire, distance):\n",
    "    \n",
    "    #Get the 1st 256 x 256 x 12 channelsarray\n",
    "    j=0\n",
    "    l=0\n",
    "    while l<=0 and j<len(fire_perims):\n",
    "    \n",
    "        if type(all_fires['geometry'][j]) == shapely.geometry.polygon.Polygon:\n",
    "            test_polygon = all_fires['geometry'][j]\n",
    "            poly_center = np.array(test_polygon.representative_point()) \n",
    "            polygonbounds = getAutomatedBbox(poly_center[0], poly_center[1], distance)\n",
    "        \n",
    "        elif type(all_fires['geometry'][j]) == shapely.geometry.multipolygon.MultiPolygon:\n",
    "            test_polygon = all_fires['geometry'][j][0]\n",
    "            poly_center = np.array(test_polygon.representative_point()) \n",
    "            polygonbounds = getAutomatedBbox(poly_center[0], poly_center[1], distance)\n",
    "\n",
    "        (timeparams, fireDate) =getSearchIntervalNew(fire_perims,j, isFire)\n",
    "\n",
    "        image_arr = getDownloadImageArray(polygonbounds, timeparams, fireDate)\n",
    "        l = len(image_arr)\n",
    "        if l>0:\n",
    "            image_arr = np.expand_dims(image_arr, axis = 3)    \n",
    "        j=j+1\n",
    "\n",
    "    for i in range(j,len(fire_perims)):  #for i in range(len(fire_perims)):\n",
    "\n",
    "        if type(all_fires['geometry'][i]) == shapely.geometry.polygon.Polygon:\n",
    "            test_polygon = all_fires['geometry'][i]\n",
    "            poly_center = np.array(test_polygon.representative_point()) \n",
    "            polygonbounds = getAutomatedBbox(poly_center[0], poly_center[1], distance)\n",
    "        \n",
    "        elif type(all_fires['geometry'][i]) == shapely.geometry.multipolygon.MultiPolygon:\n",
    "            test_polygon = all_fires['geometry'][i][0]\n",
    "            poly_center = np.array(test_polygon.representative_point()) \n",
    "            polygonbounds = getAutomatedBbox(poly_center[0], poly_center[1], distance)\n",
    "\n",
    "        (timeparams, fireDate) =getSearchIntervalNew(fire_perims,i, isFire)\n",
    "      \n",
    "        image_i = getDownloadImageArray(polygonbounds, timeparams, fireDate)\n",
    "        \n",
    "        \n",
    "        if len(image_i)>0:\n",
    "            image_i = np.expand_dims(image_i, axis = 3)           \n",
    "            image_arr = np.concatenate((image_arr, image_i), axis = -1)\n",
    "        \n",
    "    \n",
    "    return image_arr\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-channel Image Arrays Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Fire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "isFire = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.642478227615356\n",
      "(256, 256, 8, 5)\n"
     ]
    }
   ],
   "source": [
    "distance = 0.5\n",
    "\n",
    "#Run on small fire array\n",
    "start = time.time()\n",
    "fire_perims_small = fire_perims[0:5]  #final image\n",
    "final_image_array = downloadAllBurnImagesAsArray(fire_perims_small, isFire, distance)\n",
    "print(time.time() - start)\n",
    "print(final_image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 5000\n",
    "fire_perims_1st5000 = fire_perims[start:end].reset_index()  #final image\n",
    "\n",
    "final_image_array_1st5000 = downloadAllBurnImagesAsArray(fire_perims_1st5000, isFire, distance)\n",
    "#np.save('fire_data_1st5000.npy', final_image_array_1st5000) # save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save fire array to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'class_fire_True_data' + str(start) + 'to' + str(end) + '.npy'\n",
    "np.save(filename, final_image_array_1st5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Non-Fire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "isFire = False\n",
    "distance = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Run on chunks of 5000 again\n",
    "print(isFire)\n",
    "start = 0\n",
    "end = 5000\n",
    "fire_perims_1st5000 = fire_perims[start:end].reset_index()  #final image\n",
    "\n",
    "final_image_array_1st5000 = downloadAllBurnImagesAsArray(fire_perims_1st5000, isFire, distance)\n",
    "\n",
    "#final_image_array_1st5000nofire = downloadAllBurnImagesAsArray(fire_perims_1st5000, isFire, distance)\n",
    "#np.save('non_fire_data_1st5000.npy', final_image_array_1st5000nofire) # save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save non fire array to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'class_fire_False_data' + str(start) + 'to' + str(end) + '.npy'\n",
    "np.save(filename, final_image_array_1st5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load fire and non fire arrays from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_arr = np.load('fire_data.npy') # load\n",
    "non_fire_arr = np.load('non_fire_data.npy') # load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Class Non-fire: Get additional random lat long points of non-fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadRandomImages(distance, num):\n",
    "    lat_center = np.random.uniform(35.0000, 45.000)\n",
    "    lon_center = np.random.uniform(-120.000, -90.000)\n",
    "        \n",
    "    polygonbounds = getAutomatedBbox(lon_center, lat_center, distance)\n",
    "    timeparams = '2018-03-01/2020-03-01'\n",
    "    date = '2020'\n",
    "    image_arr = getDownloadImageArray(polygonbounds, timeparams, date)\n",
    "    image_arr = np.expand_dims(image_arr, axis = 3) \n",
    "    for i in range(1,num): \n",
    "        random_arr = getDownloadImageArray(polygonbounds, timeparams, date)\n",
    "        if len(random_arr)>0:\n",
    "            random_arr = np.expand_dims(random_arr, axis = 3)         \n",
    "            image_arr = np.concatenate((image_arr, random_arr), axis = -1)\n",
    "    \n",
    "    return image_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = downloadRandomImages(distance, 50)  # change 50 to however many random images we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "isFire = False\n",
    "print(isFire)\n",
    "start = 0\n",
    "end = 1000\n",
    "num = end - start\n",
    "random_array = downloadRandomImages(distance, num)  # num is however many random images we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save random array to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'class_fire_False_random_data' + str(start) + 'to' + str(end) + '.npy'\n",
    "np.save(filename, random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load random (non-fire) array from file and merge with other nonfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_arr = np.load('randomX_train_val_test.npy') # load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_non_fire_arr = np.concatenate((random_arr, non_fire_arr), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See shapes of final fire and non-fire arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_arr.shape     #This is total X for train_validation_testing split with Y = class fire\n",
    "all_non_fire_arr.shape #This is total X for train_validation_testing split with Y = class no fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
